# -*- coding: utf-8 -*-
"""Face_detection_siamese_network_using_pretrained_Resnet50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/123Satyajeet123/siamese_network_face_detection/blob/main/Face_detection_siamese_network_using_pretrained_Resnet50.ipynb

## Importing Necessary Modules
"""

# Data manipulation
import numpy as np
import pandas as pd

# Data visualisation
import matplotlib.pyplot as plt

# Fastai
from fastai.vision import *
from fastai.vision.models import *

# PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.utils
import torchvision.datasets as dset

from torch import optim
from torch.utils.data import DataLoader,Dataset
from torchvision.models import *
from torchvision.datasets import ImageFolder
from torch.autograd import Variable
#import pretrainedmodels

from pathlib import Path
import sys

from glob import glob
from PIL import Image

# Importing torch and torchvision to get resnet model
import torch
import torchvision.models as models

# Loading the pre-trained ResNet-50 model with ImageNet weights
resnet = models.resnet50(pretrained=True)

# creating a custom dataset class for the triplets dataset
import torch
import os
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms

class TripletDataset(Dataset):
    def __init__(self, directory, triplet_list, transform=None):
        self.directory = directory
        self.triplet_list = triplet_list
        self.transform = transform

    def __len__(self):
        return len(self.triplet_list)

    def __getitem__(self, index):
        anchor, positive, negative = self.triplet_list[index]

        anchor_path = os.path.join(self.directory, anchor[0], anchor[1])
        positive_path = os.path.join(self.directory, positive[0], positive[1])
        negative_path = os.path.join(self.directory, negative[0], negative[1])

        anchor_img = Image.open(anchor_path).convert("RGB")
        positive_img = Image.open(positive_path).convert("RGB")
        negative_img = Image.open(negative_path).convert("RGB")

        if self.transform is not None:
            anchor_img = self.transform(anchor_img)
            positive_img = self.transform(positive_img)
            negative_img = self.transform(negative_img)

        return anchor_img, positive_img, negative_img

"""## Extracting Images from **IFW** Dataset"""

import zipfile

# Specify the path to the zip file
zip_file_path = '/content/drive/MyDrive/lfw_new.zip'  # Change to your actual file path

# Specify the directory where you want to extract the contents
extracted_path = '/extracted/'  # Change to your desired extraction path

# Create the target directory if it doesn't exist
import os
os.makedirs(extracted_path, exist_ok=True)

# Extract the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_path)

print(f'Zip file extracted to {extracted_path}')

ROOT = "/etracted/lfw_new"

ROOT = "/extracted/lfw_new"
import random
import os

def split_dataset(directory, split=0.9):
    folders = os.listdir(directory)
    num_train = int(len(folders)*split)

    random.shuffle(folders)

    train_list, test_list = {}, {}

    # Creating Train-list
    for folder in folders[:num_train]:
        num_files = len(os.listdir(os.path.join(directory, folder)))
        train_list[folder] = num_files

    # Creating Test-list
    for folder in folders[num_train:]:
        num_files = len(os.listdir(os.path.join(directory, folder)))
        test_list[folder] = num_files

    return train_list, test_list


train_list, test_list = split_dataset(ROOT, split=0.9)
print("Length of training list:", len(train_list))
print("Length of testing list :", len(test_list))

# train_list, test list contains the folder names along with the number of files in the folder.
print("\nTest List:", test_list)

print(train_list)

"""# Creating Triplets building dataloader and converting to torch tensors"""

import os

# Creating triplets (anchor,positive,negative)
def creating_triplets(directory, folder_list, max_files=20):
    triplets = []
    folders = list(folder_list.keys())

    for folder in folders:
        path = os.path.join(directory, folder)
        files = os.listdir(path)
        num_files = len(files)

        if num_files < 2:
            continue

        for i in range(num_files-1):
            for j in range(i+1, num_files):
                anchor = (folder, f"{i}.jpg")
                positive = (folder, f"{j}.jpg")

                neg_folder = folder
                while neg_folder == folder:
                    neg_folder = random.choice(folders)
                neg_file = random.randint(0, folder_list[neg_folder]-1)
                negative = (neg_folder, f"{neg_file}.jpg")

                triplets.append((anchor, positive, negative))

    random.shuffle(triplets)
    return triplets

train_triplet = creating_triplets(ROOT, train_list)
test_triplet  = creating_triplets(ROOT, test_list)

print("Number of training triplets:", len(train_triplet))
print("Number of testing triplets :", len(test_triplet))

print("\nExamples of triplets:")
for i in range(20):
    print(train_triplet[i])

# creating a custom dataset class for the triplets dataset
import torch
import os
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms


class TripletDataset(Dataset):
    def __init__(self, directory, triplet_list, transform=None):
        self.directory = directory
        self.triplet_list = triplet_list
        self.transform = transform

    def __len__(self):
        return len(self.triplet_list)

    def __getitem__(self, index):
        anchor, positive, negative = self.triplet_list[index]

        anchor_path = os.path.join(self.directory, anchor[0], anchor[1])
        positive_path = os.path.join(self.directory, positive[0], positive[1])
        negative_path = os.path.join(self.directory, negative[0], negative[1])

        anchor_img = Image.open(anchor_path).convert("RGB")
        positive_img = Image.open(positive_path).convert("RGB")
        negative_img = Image.open(negative_path).convert("RGB")

        if self.transform is not None:
            anchor_img = self.transform(anchor_img)
            positive_img = self.transform(positive_img)
            negative_img = self.transform(negative_img)

        return anchor_img, positive_img, negative_img

tripletDataset1 = TripletDataset(
    ROOT,
    train_triplet,
    transform=transforms.Compose(
        [
            transforms.Resize((224, 224)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    ),
)
tripletDataset2 = TripletDataset(
    ROOT,
    test_triplet,
    transform=transforms.Compose(
        [
            transforms.Resize((224, 224)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    ),
)

tripletDataset1 = torch.load('tripletDataset1.pt')
tripletDataset2 = torch.load('tripletDataset2.pt')

trainLoader = torch.utils.data.DataLoader(
    tripletDataset1, batch_size=64, shuffle=True, num_workers=2
)
testLoader = torch.utils.data.DataLoader(
    tripletDataset2, batch_size=64, shuffle=True, num_workers=2
)

"""# Building the Siamese Network using Pretrained Resnet and custom layers"""

class SiameseNetwork(nn.Module):
    def __init__(self, num_hidden_units_fc1=256, num_hidden_units_fc2=128):
        super(SiameseNetwork, self).__init__()
        self.resnet = models.resnet50(pretrained=True)
        for param in self.resnet.parameters():
            param.requires_grad = False  # Make the ResNet layers non-trainable

        self.resnet.fc = nn.Linear(2048, num_hidden_units_fc1)
        self.fc1 = nn.Linear(num_hidden_units_fc1, num_hidden_units_fc2)
        self.fc2 = nn.Linear(num_hidden_units_fc2, 2)

    def forward(self, x):
        x = self.resnet(x)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

siamese = SiameseNetwork()
print(siamese)

"""## Custom loss function for **triplet loss** as we are using triplets instead or regular (Anchor and Positive)"""

class TripletLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(TripletLoss, self).__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative):
        distance_positive = F.pairwise_distance(anchor, positive)
        distance_negative = F.pairwise_distance(anchor, negative)
        losses = torch.relu(distance_positive - distance_negative + self.margin)
        return losses.mean()

triplet_loss = TripletLoss()

"""#Function for Training the Siamese Network and using the custom loss function to minimize"""

import torch.optim as optim

optimizer = optim.Adam(siamese.parameters(), lr=0.001)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Move your Siamese network and optimizer to the same device
siamese.to(device)
# create a function to train the model
#optimizer = optimizer.to(device)

def train_siamese(model, train_loader, optimizer, epoch, log_interval=100):
    model.train()
    losses = []
    total_loss = 0
    for batch_idx, (anchor, positive, negative) in enumerate(train_loader):
        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)
        optimizer.zero_grad()
        anchor = anchor.to(device)
        positive = positive.to(device)
        negative = negative.to(device)

        # Forward pass
        anchor_output = model(anchor)
        positive_output = model(positive)
        negative_output = model(negative)


        # Calculate the triplet loss
        loss = triplet_loss(anchor_output, positive_output, negative_output)

        # Backpropagation and optimization
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        if batch_idx % log_interval == 0:
            print(
                "Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}".format(
                    epoch,
                    batch_idx * len(anchor),
                    len(train_loader.dataset),
                    100.0 * batch_idx / len(train_loader),
                    loss.item(),
                )
            )
            losses.append(total_loss / log_interval)
            total_loss = 0
    return losses

# training the model
import torch
import torch.nn as nn
import torch.nn.functional as F

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

num_epochs = 3
log_interval = 100

train_losses = []
for epoch in range(1, num_epochs + 1):
    train_loss = train_siamese(siamese, trainLoader, optimizer, epoch, log_interval)
    train_losses.extend(train_loss)

# plot the training loss
plt.plot(train_losses)

#Replace 'your_model' with the actual variable containing your trained model
 torch.save(siamese.state_dict(), '/content/drive/My Drive/siamese_resnet_model.pth')

correct = 0
total = 0

# Put your model in evaluation mode
siamese.eval()

with torch.no_grad():
    for data in testLoader:  # Assuming you have a DataLoader for testing
        inputs, labels = data
        outputs = siamese(inputs)

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'Accuracy: {accuracy:.2f}%')



# check how many images are correctly classified by the model on the test set and how many are incorrectly classified

def test_siamese(model, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for anchor, positive, negative in test_loader:
            anchor = anchor.to(device)
            positive = positive.to(device)
            negative = negative.to(device)
            anchor_output = model(anchor)
            positive_output = model(positive)
            negative_output = model(negative)
            test_loss += triplet_loss(anchor_output, positive_output, negative_output).item()

            #checks if the anchor is closer to the positive image than to the negative image
            correct += ((anchor_output < positive_output) & (anchor_output < negative_output)).type(torch.float).sum().item()
    test_loss /= len(test_loader.dataset)
    print("Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n".format(
        test_loss, correct, len(test_loader.dataset),
        100.0 * correct / len(test_loader.dataset)))

test_siamese(siamese, testLoader)